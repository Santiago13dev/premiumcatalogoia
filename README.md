# ğŸ§  CatÃ¡logo Premium de Componentes de IA

Â¡Bienvenido a tu propio **CatÃ¡logo de Componentes de Inteligencia Artificial**! Esta aplicaciÃ³n te permite explorar, filtrar, y **probar prompts en vivo** usando modelos locales como `llama3` gracias a [Ollama](https://ollama.com/).

---

## ğŸŒŸ CaracterÃ­sticas

- âœ… Listado dinÃ¡mico de componentes de IA (modelos, datasets, prompts)
- ğŸ” Filtros por tipo y etiquetas
- ğŸ§ª Probador de prompts en vivo con `llama3` local
- ğŸ’» Backend con Node.js + Express para procesar prompts
- ğŸ’… UI moderna con React + TailwindCSS + Vite

---

## ğŸ“‚ Estructura del proyecto

```
premiumcatalogoia/
â”œâ”€â”€ public/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ComponentCard.jsx
â”‚   â”‚   â”œâ”€â”€ Modal.jsx
â”‚   â”‚   â””â”€â”€ PromptTester.jsx
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ components.json
â”‚   â”œâ”€â”€ App.jsx
â”‚   â””â”€â”€ index.css
â”œâ”€â”€ server/
â”‚   â””â”€â”€ server.js
â”œâ”€â”€ package.json
â”œâ”€â”€ tailwind.config.js
â””â”€â”€ vite.config.js
```

---

## ğŸš€ InstalaciÃ³n y ejecuciÃ³n

### 1. Clona el repositorio
```bash
git clone https://github.com/tuusuario/premiumcatalogoia.git
cd premiumcatalogoia
```

### 2. Instala las dependencias
```bash
npm install
```

### 3. Instala y configura [Ollama](https://ollama.com/)
```bash
# Instala el modelo Llama3 si aÃºn no lo tienes
ollama run llama3
```

### 4. Inicia el backend
```bash
npm run start
# Corre en http://localhost:3000
```

### 5. En otra terminal, inicia el frontend
```bash
npm run dev
# Corre en http://localhost:5173
```

---

## ğŸ§ª CÃ³mo usar el probador de prompts

1. Selecciona un componente de tipo `prompt`
2. En el modal, ingresa el texto en el campo de entrada
3. Haz clic en â€œProbar Promptâ€
4. VerÃ¡s la respuesta generada por IA en tiempo real

> Nota: los prompts deben tener `{input}` para marcar dÃ³nde se reemplaza el texto del usuario.

---

## ğŸ“¦ JSON de componentes de ejemplo

```json
{
  "id": "1",
  "name": "Resumidor de texto",
  "type": "prompt",
  "tags": ["resumen", "texto"],
  "prompt": "Resume el siguiente texto:\n\n{input}",
  "description": "Devuelve un resumen del texto proporcionado",
  "usage": "POST /api/try-prompt\n{ prompt: '...', input: '...' }"
}
```

---

## ğŸ’¡ Futuras mejoras

| Idea | Estado |
|------|--------|
| Editor visual de prompts | ğŸŸ¡ Pendiente |
| Soporte para mÃ¡s modelos (Mistral, Phi) | ğŸŸ¡ En camino |
| ExportaciÃ³n de componentes en Markdown/ZIP | ğŸ”œ |
| Subida de imagen o PDF para anÃ¡lisis | ğŸ”œ |

---

## ğŸ§‘â€ğŸ’» Autor

Desarrollado con ğŸ’™ por **Santiago RodrÃ­guez**  
ğŸ“ Full-stack Developer | DevOps | AI Enthusiast  
ğŸ“« [TuCorreo@ejemplo.com]

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.